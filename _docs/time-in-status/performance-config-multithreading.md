---
title: Performance settings - multithreading
key: time-in-status
---
<p>
В зависимости от возможностей вашего сервера вы можете выделить дополнительные ресурсы которые плагин может использовать.
Основные вычисления хорошо обрабатываются параллельно и дополнительные потоки могут сильно ускорить обработку.
Разница будет более заметна на больших объемах данных. 
</p>

<p>
Во время простоя плагина выделенные ресурсы остаются доступны системе. Они используются только при выполнении задач.
</p>

<p>
Статистика размера очередей доступна по url: {baseUrl}/rest/jibrok/timeinstatus/1.0/performanceConfig/multithreading/executors/queues
</p>

All settings:<br>
<p style="text-align: center;"><a href="/uploads/time-in-status/performance-config-multithreading/settings-multithreading.png"><img src="/uploads/time-in-status/performance-config-multithreading/settings-multithreading.png" alt="" width="300"/></a></p>


### Listeners ###
<p>
Вы можете настроить асинхронную обработку событий. Это уберет какие-либо задежки в UI вызванные обработкой событий.
В этом случае пользовательский интерфейс не будет дожидаться выполнения обработки событий, которые будут выполняться в фонов режиме.
</p>


Актуально для:
* Нагруженных систем.
* Для таймеров и секундомеров которые реагируют на редактирование задач и переходы между статусами. Эти операции довольно медленные сами по себе.
* Работы [Autotrack](/docs/time-in-status/autotrack/) где отслеживается вход-выход пользователя.


### Common ### 

Следующий функционал использует многопоточность:
* [JQL functions](/docs/time-in-status/user-help-info/) - расчет данных в реальном времени, сравнение значений.
* Timer - обработка событий, пересчет запущенных таймеров при редактирование целей.
* Stopwatch - обработка событий.
* [Manual control](/docs/time-in-status/manual-action-by-jql/) - запуск и остановка таймеров и секундомеров по jql.

Основной бенифициан исопльзования многопоточности - функции поиска по данным в реальном времени. И как следствие рабочие столы и фильтры использующие эти функции.


Доступны два режима многопоточности: 
*  Установка количества используемых потоков в ручную. Максимальное количество доступных потоков ограничено количеством cpu доступных jvm.
При установке максимального количества вы позволяете плагину нагружать все ядра процессора одновременно.
Мы не рекомендуем так делать. Это можете привести к фризам у всех пользователей системы в моменты когда процессор будет использоваться на 100%.
Эта настройка подбирается индивидуально(возможно динамически) в зависимости от ваших серверов, окружения и нагрузки которую генерируют ваши пользователи.
  
* Использование stream api: эта настройка просто передает все задачи jvm на выполнение и jvm сама определяет сколько ресурсов она может выделить на решение этих задач.
Эта настройка показывает максимальный прирост в производительности. Но также обладает одной проблемой (как и использование максимального количества потоков) - используется общий пул для выполнения задач. И задачи из плагина могу задерживать другие вычисления jvm. Это может приводить к периодическим задержкам в самых разных местах. [more info](https://www.google.com/search?q=Think+Twice+Before+Using+Java+8+Parallel+Streams&oq=Think+Twice+Before+Using+Java+8+Parallel+Streams)
  

Если используется 1 поток, то вычисления будет производить текущий поток сессии пользователя.<br>
**Если используется больше одного потока, то они берутся из одного общего для всех пользователей пула потоков**.<br> 

Проблемы задержек характерны для больших и тяжелых вычислений. Например расчет времени в статусе для 1000000 задач это довольно тяжелая операция. Если дать плагину возможность загружать процессор полностью, то это может вызвать ожидаемые тормоза Jira во время выполнения таких расчетов.
Чтобы избежать необоснованно тяжелых вычислений есть лимиты на количество рассчитываемых задач в рамках одного запроса.
Это позволит практически линейно уменьшить задержку. 
Если 1000000 задач выполняются N секунд и создают задержку в N секунд. 
То уменьшение количество задач в 100 раз уменьшит время задержки в 100 раз.

see [Performance settings - JQL: Count limit](/docs/time-in-status/performance-config-jql/)



Ниже представлена таблица с экспериментальными данными. Таблица построена на реальных данных, но служит исключительно для демонстрации динамики изменения времени выполнения запроса в зависимости от настроек.

<p style="text-align: center;"><a href="/uploads/time-in-status/performance-config-multithreading/local-test-issue-in-timeinstatus.png"><img src="/uploads/time-in-status/performance-config-multithreading/local-test-issue-in-timeinstatus.png" style="width:600px"/></a></p>

Механизм еще не исчерпал всех возможностей оптимизации. Он будет улучшаться в новых версиях приложения.


В общем случае нужно ориентироваться на свободные ресурсы процессора.

### Reports ### 

Отчеты обрабатываются отдельными очередями которые тоже можно настроить.
У отчетов три очереди. 
* Manual - в этой очереди обрабатываются отчеты генерацию которых пользователи запустили вручную(открыли интерфейс и нажали кнопку или вызвали api).
Обработка таких отчетов отдельно позволит пользователю быстрее получить свежие данные в отчете. И не ждать пока обновляются другие отчеты.  

Если генерация отчета запущена автоматически по расписанию, то используется одна из следующих очередей.
* Если отчет использует не большое количество запросов, то он обрабатывается очередью для быстрых отчетов.<br>
Это позволяет небольшим отчетам обновляться быстрее и не ждать пока обработаются медленные отчеты.
* Если отчет строится на основе большого количества запросов, то он попадает в очередь для медленных отчетов. 
Время генерации которых может занимать продолжительное время.

Граница для попадания в быструю и медленную очередь задается отдельным параметром в виде количества задач.

**Изменение количества потоков происходит не мгновенно. Оно изменится как только пул потоков выполнит текущие задачи(может пройти несколько минут).** 
